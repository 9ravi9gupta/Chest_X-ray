{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0x1P5_5vTbIm"
   },
   "outputs": [],
   "source": [
    "def preprocess_data():\n",
    "  import numpy as np # linear algebra\n",
    "  import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "  import matplotlib.pyplot as plt # basic plotting\n",
    "  import seaborn as sns \n",
    "\n",
    "\n",
    "  xray_data = pd.read_csv('./Data_Entry_2017.csv')\n",
    "\n",
    "  # see how many observations there are\n",
    "  num_obs = len(xray_data)\n",
    "  print('Number of observations:',num_obs)\n",
    "\n",
    "  # examine the raw data before performing pre-processing\n",
    "  xray_data.head(5) # view first 5 rows\n",
    "  #xray_data.sample(5) # view 5 randomly sampled rows\n",
    "  \n",
    "  \n",
    "  \n",
    "  from glob import glob\n",
    "  #import os # already imported earlier\n",
    "\n",
    "  my_glob = glob('./input_images/images*/*.png')\n",
    "  print('Number of Observations: ', len(my_glob)) # check to make sure I've captured every pathway, should equal 112,120\n",
    "  \n",
    "  \n",
    "  \n",
    "  full_img_paths = {os.path.basename(x): x for x in my_glob}\n",
    "  xray_data['full_path'] = xray_data['Image Index'].map(full_img_paths.get)\n",
    "  \n",
    "  #---for removing null path\n",
    "  df = xray_data['full_path'].dropna()\n",
    "  new_xray_data = pd.merge(xray_data, df, how='right')\n",
    "  \n",
    "  #----for making seperate dataframe of specific diseases\n",
    "  df1 = new_xray_data[new_xray_data['Finding Labels']=='Atelectasis']\n",
    "  df2 = new_xray_data[new_xray_data['Finding Labels']=='Infiltration']\n",
    "  df3 = new_xray_data[new_xray_data['Finding Labels']=='Effusion']\n",
    "  \n",
    "  n = int(df2.shape/5)  #-- sampling the 'No Finding' labels\n",
    "  df4 = new_xray_data[new_xray_data['Finding Labels']=='No Finding'].iloc[:n, :] # taking small sample beacuse to avoid baised data\n",
    "  \n",
    "  cleaned_df = pd.concat([df1,df2,df3,df4], ignore_index=True)\n",
    "  \n",
    "  #--for shuffling data\n",
    "  from sklearn.utils import shuffle\n",
    "  cleaned_df = shuffle(cleaned_df)\n",
    "  \n",
    "  \n",
    "  dummy_labels = ['No Finding', 'Atelectasis', 'Infiltration','Effusion'] # taken from paper\n",
    "\n",
    "  # One Hot Encoding of Finding Labels to dummy_labels\n",
    "  for label in dummy_labels:\n",
    "      cleaned_df[label] = cleaned_df['Finding Labels'].map(lambda result: 1.0 if label in result else 0)\n",
    "  cleaned_df.head() # check the data, looking good!\n",
    "  \n",
    "  \n",
    "  cleaned_df['target_vector'] = cleaned_df.apply(lambda target: [target[dummy_labels].values], 1).map(lambda target: target[0])\n",
    "  \n",
    "  \n",
    "  \n",
    "    # split the data into a training and testing set\n",
    "  from sklearn.model_selection import train_test_split\n",
    "  train_set, test_set = train_test_split(cleaned_df, test_size = 0.2, random_state = 1993)\n",
    "\n",
    "  # quick check to see that the training and test set were split properly\n",
    "  print('training set - # of observations: ', len(train_set))\n",
    "  print('test set - # of observations): ', len(test_set))\n",
    "  print('prior, full data set - # of observations): ', len(cleaned_df))\n",
    "  \n",
    "  \n",
    "  \n",
    "  #--Preparing data generator for feeding data into model--\n",
    "  from keras.preprocessing.image import ImageDataGenerator\n",
    "  data_gen = ImageDataGenerator(\n",
    "          rescale=1./255,\n",
    "          shear_range=0.2,\n",
    "          zoom_range=0.2,\n",
    "          rotation_range=20,\n",
    "          width_shift_range=0.2,\n",
    "          height_shift_range=0.2,\n",
    "          horizontal_flip=True)\n",
    "\n",
    "\n",
    "  train_gen = data_gen.flow_from_dataframe(train_set, directory=None, x_col='full_path', y_col='Finding Labels', target_size=(224, 224), color_mode='rgb', classes=None, class_mode='categorical', batch_size=128, shuffle=True, seed=None, save_to_dir=None, save_prefix='', save_format='png', subset=None, interpolation='nearest', drop_duplicates=True)\n",
    "  test_X, test_Y = next(data_gen.flow_from_dataframe(test_set, directory=None, x_col='full_path', y_col='Finding Labels', target_size=(224, 224), color_mode='rgb', classes=None, class_mode='categorical', batch_size=128, shuffle=True, seed=None, save_to_dir=None, save_prefix='', save_format='png', subset=None, interpolation='nearest', drop_duplicates=True))\n",
    "\n",
    "  \n",
    "  \n",
    "  return(train_gen, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wvlX5uLtTbFq"
   },
   "outputs": [],
   "source": [
    "def model():\n",
    "\n",
    "  from keras.applications.vgg16 import VGG16\n",
    "  from keras.layers import Dense, Input, Conv2D, BatchNormalization, Flatten, Dropout\n",
    "  from keras.models import Model\n",
    "  \n",
    "  model = VGG16(include_top=False, input_shape=(224,224,3))\n",
    "  \n",
    "  x = Flatten()(model.output)\n",
    "\n",
    "  \n",
    "  x = Dense(units=1024, activation='relu', kernel_initializer='he_normal')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  x = Dense(units=1024, activation='relu', kernel_initializer='he_normal')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Dropout(0.2)(x)\n",
    "\n",
    "  x = Dense(units=4,activation='softmax')(x)\n",
    "  \n",
    "  custom_model = Model(input=model.input, output=x)\n",
    "  \n",
    "  return(custom_model)\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4RGWM8wLTbC3"
   },
   "outputs": [],
   "source": [
    "def training():\n",
    "  \n",
    "  train_gen, test_X, test_Y = preprocess_data()\n",
    "  \n",
    "  custom_model = model()\n",
    "  \n",
    "  \n",
    "  for layer in custom_model.layers[:11]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "    \n",
    "  custom_model.compile(loss='categorical_crossentropy',\n",
    "                     optimizer='adam',\n",
    "                     metrics=['accuracy'])\n",
    "  \n",
    "  #---making checkpoints for storing best weights during training\n",
    "  from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "  checkpointer = ModelCheckpoint(filepath='weights.best.{epoch:02d}-{val_loss:.2f}.hdf5', verbose=1, save_best_only = True)\n",
    "  callbacks_list = [checkpointer]\n",
    "  \n",
    "  custom_model.fit_generator(generator = train_gen, steps_per_epoch = 20, epochs = 10, validation_data = (test_X, test_Y))\n",
    "  \n",
    "  return(custom_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mbmKkIS2TbAD"
   },
   "outputs": [],
   "source": [
    "trained_model = training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GkOpOTcCdxy_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QvuI_FqYdAek"
   },
   "source": [
    "**Saving Model Weigths and Architecture** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ogTMR8h4c1y8"
   },
   "outputs": [],
   "source": [
    "custom_model.save_weights('xray.h5')\n",
    "\n",
    "model_json = custom_model.to_json()\n",
    "\n",
    "with open('xray_network_arch.json', 'w') as file:\n",
    "  file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_4xGujfSc1wB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1uuFczUpd2eX"
   },
   "source": [
    "**Loading Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FQfo1oD5d6Ne"
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "with open('xray_network_arch.json', 'r') as json_file:\n",
    "  json_model = json_file.read()\n",
    "  \n",
    "\n",
    "trained_model = model_from_json(json_model)\n",
    "trained_model.load_weights('./drive/My Drive/model/xray_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-QyeXUgEd65y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qr_Uw8i_c3p8"
   },
   "source": [
    "# **Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tzcqHh6-Ta9h"
   },
   "outputs": [],
   "source": [
    "def prediction(img_path, trained_model):\n",
    "  from keras.preprocessing import image\n",
    "  \n",
    "  img = image.load_img(path=img_path, target_size=(224,224,3))\n",
    "  img_arr = image.img_to_array(img)\n",
    "  img_arr.resize(1,224,224,3)\n",
    "  \n",
    "  prediction = moodel.predict(img_arr)[0]\n",
    "  \n",
    "  return(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ijk8WcejTa63"
   },
   "outputs": [],
   "source": [
    "img_path = './input_images/images_3/00005274_007.png'\n",
    "prediction_value = prediction(img_path, trained_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ld9RSIiTa4S"
   },
   "outputs": [],
   "source": [
    "output = np.argmax(prediction_value)\n",
    "\n",
    "if output == 0:\n",
    "  print('No Finding')\n",
    "  \n",
    "elif output == 1:\n",
    "  print('Atelectasis')\n",
    "  \n",
    "elif output == 2:\n",
    "  print('Infiltration')\n",
    "  \n",
    "elif ouput == 3:\n",
    "  print('Effusion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2HRi2zuJTa1e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C7VGawxITayX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Chest_X_ray.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
